# input / output

## Brief:
The goal of this assignment is to create a collection of audio-based input/outputs with Javascript for everyone to refine and reference over the course of this workshop. Over the next few weeks, we will be using these i/o's as a starting point for critiques and discussions on what a cross-sensory interaction can be.

## Considerations
- Which words are optional in your commands?
- Can you identify the limitations of this library?
- How do you engage with the limits of this library?
- Should the user be aware of these limits?
- What do you wish you could tell your computer to do?
- What existing digital action can you translate to speech? How does that action change?
- Tactility provides immediate haptic responsiveness to our actions. How might we translate this expectation into speech?
- How might you sing to your computer?
- What kinds of words can `annyang` understand easily? Which ones are harder for it to interpret?
- In what environment are you comfortable talking to your computer?

## Requirements:
- Each sketch should have its own directory (you can just make 5 copies of the [speech starter pack](/files/speech_starter_pack.zip))
- Each sketch should have a unique input command (try varying the length or amount of inputs)
- Each sketch&rsquo;s output should be visually distinct
- You should use each command type (`explicit` `single variable` `splat`, and `optional command`) at least once.

## Timeline

### Week 1
For the first week you will create 5 separate input/output sketches, each exploring a different type of speech-based input and visual output.

### Week 2
Expand 3 (or 4 if you continue working in a group) of your input/outputs to include all states of feedback.


## Context:
### States of Feedback
For this class, we want to break down an interaction into the **following states of feedback**:

1. Show ready state
2. Begin input
3. Acknowledge received input
4. Show output
5. Error state

For the _first week_ of this assignment, we will be focusing on steps 2 and 4.


## Goals:
- Learn to use Javascript as a prototyping tool
- get acquainted with the speech library Annyang
- explore simple audio input interactions
- Create a repository of interactions through the quick iteration of ideas


## Interaction Examples:
- A Google produced prototype for the Speech API: [Speech Color Changer](https://mdn.github.io/web-speech-api/speech-color-changer/)
- A phone-linked website designed by HAWRAF: [1833marcive](http://1833marcive.com/)
- A generative web-to-print catalogue: [A.I.R. Gallery Biennial](https://letstrylisteningagain.org/)
- A simple interaction with a lot of feedback: [clickclickclick.click](https://clickclickclick.click/)
- An early net art work exploring html elements by Alexei Shulgin: ["Form"](http://variants.artbase.rhizome.org/Q1249/)
- A framework that offers UI defaults [Semantic UI](https://semantic-ui.com/)
- A html/css form workshop: [htmloutput.risd.gd](http://htmloutput.risd.gd)
- [The Sound Game](http://tamarashopsin.com/soundgame/)
- [Let me google that for you](http://letmegooglethat.com/?q=is+this+an+input%3F)

